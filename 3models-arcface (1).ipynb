{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-innocent",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-09T10:42:46.321938Z",
     "iopub.status.busy": "2021-05-09T10:42:46.320411Z",
     "iopub.status.idle": "2021-05-09T10:42:46.328621Z",
     "shell.execute_reply": "2021-05-09T10:42:46.329092Z"
    },
    "papermill": {
     "duration": 0.028776,
     "end_time": "2021-05-09T10:42:46.329294",
     "exception": false,
     "start_time": "2021-05-09T10:42:46.300518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frozen-exemption",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:42:46.364888Z",
     "iopub.status.busy": "2021-05-09T10:42:46.364250Z",
     "iopub.status.idle": "2021-05-09T10:42:54.757386Z",
     "shell.execute_reply": "2021-05-09T10:42:54.756537Z"
    },
    "papermill": {
     "duration": 8.413078,
     "end_time": "2021-05-09T10:42:54.757517",
     "exception": false,
     "start_time": "2021-05-09T10:42:46.344439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import math\n",
    "import random \n",
    "import os \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import pickle\n",
    "get_cpkl = exec\n",
    "import torch \n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm \n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import albumentations as A \n",
    "\n",
    "from torch.utils.data import Dataset \n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "import dill as pickle5\n",
    "import gc\n",
    "import cupy\n",
    "import cudf\n",
    "import cuml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "antique-renewal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:42:54.793034Z",
     "iopub.status.busy": "2021-05-09T10:42:54.792223Z",
     "iopub.status.idle": "2021-05-09T10:42:54.794791Z",
     "shell.execute_reply": "2021-05-09T10:42:54.794254Z"
    },
    "papermill": {
     "duration": 0.021968,
     "end_time": "2021-05-09T10:42:54.794900",
     "exception": false,
     "start_time": "2021-05-09T10:42:54.772932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    img_size = 512\n",
    "    batch_size = 12\n",
    "    seed = 42\n",
    "    \n",
    "    device = 'cuda'\n",
    "    classes = 11014\n",
    "    \n",
    "    img_size1 = 640\n",
    "    model_name1 = 'eca_nfnet_l1'\n",
    "    model_path1 = '../input/fdgfdgdfgdfg/EfficientNetB3_NF_M0.7_512_42.h5'\n",
    "    \n",
    "    img_size2 = 384\n",
    "    model_name2 = 'efficientnet_b3'\n",
    "    model_path2 = '../input/fdgfdgdfgdfg/efficientnet-1.1.0-SW-py3-none-any.whl'\n",
    "    \n",
    "    scale = 30 \n",
    "    margin = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corresponding-radical",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:42:54.830205Z",
     "iopub.status.busy": "2021-05-09T10:42:54.829717Z",
     "iopub.status.idle": "2021-05-09T10:43:02.795422Z",
     "shell.execute_reply": "2021-05-09T10:43:02.794964Z"
    },
    "papermill": {
     "duration": 7.985395,
     "end_time": "2021-05-09T10:43:02.795556",
     "exception": false,
     "start_time": "2021-05-09T10:42:54.810161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "# df = pd.concat([df,df,df[:2000]]).reset_index(drop=True)\n",
    "# image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "\n",
    "df_cu = cudf.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "premier-drive",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:02.838409Z",
     "iopub.status.busy": "2021-05-09T10:43:02.837553Z",
     "iopub.status.idle": "2021-05-09T10:43:02.845430Z",
     "shell.execute_reply": "2021-05-09T10:43:02.845869Z"
    },
    "papermill": {
     "duration": 0.034563,
     "end_time": "2021-05-09T10:43:02.846010",
     "exception": false,
     "start_time": "2021-05-09T10:43:02.811447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finished-increase",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:02.884369Z",
     "iopub.status.busy": "2021-05-09T10:43:02.883736Z",
     "iopub.status.idle": "2021-05-09T10:43:02.889305Z",
     "shell.execute_reply": "2021-05-09T10:43:02.889716Z"
    },
    "papermill": {
     "duration": 0.026799,
     "end_time": "2021-05-09T10:43:02.889856",
     "exception": false,
     "start_time": "2021-05-09T10:43:02.863057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "grateful-bicycle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:02.926559Z",
     "iopub.status.busy": "2021-05-09T10:43:02.925365Z",
     "iopub.status.idle": "2021-05-09T10:43:02.927682Z",
     "shell.execute_reply": "2021-05-09T10:43:02.928100Z"
    },
    "papermill": {
     "duration": 0.022546,
     "end_time": "2021-05-09T10:43:02.928217",
     "exception": false,
     "start_time": "2021-05-09T10:43:02.905671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def masked_categorical_crossentropy(output,target):\n",
    "    y_true_masked = target[target!= -100]\n",
    "    y_pred_masked = output[target!= -100]\n",
    "    loss =  nn.CrossEntropyLoss()(y_pred_masked,y_true_masked)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "representative-connection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:02.963761Z",
     "iopub.status.busy": "2021-05-09T10:43:02.963230Z",
     "iopub.status.idle": "2021-05-09T10:43:02.966987Z",
     "shell.execute_reply": "2021-05-09T10:43:02.966468Z"
    },
    "papermill": {
     "duration": 0.023053,
     "end_time": "2021-05-09T10:43:02.967092",
     "exception": false,
     "start_time": "2021-05-09T10:43:02.944039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions1'], row['image_predictions2'], row['text_predictions'], row['phash_predictions']])\n",
    "    return ' '.join( np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incorporated-memorial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.004478Z",
     "iopub.status.busy": "2021-05-09T10:43:03.003993Z",
     "iopub.status.idle": "2021-05-09T10:43:03.007181Z",
     "shell.execute_reply": "2021-05-09T10:43:03.007538Z"
    },
    "papermill": {
     "duration": 0.024363,
     "end_time": "2021-05-09T10:43:03.007684",
     "exception": false,
     "start_time": "2021-05-09T10:43:02.983321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outer-student",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.043870Z",
     "iopub.status.busy": "2021-05-09T10:43:03.043334Z",
     "iopub.status.idle": "2021-05-09T10:43:03.055012Z",
     "shell.execute_reply": "2021-05-09T10:43:03.054554Z"
    },
    "papermill": {
     "duration": 0.030948,
     "end_time": "2021-05-09T10:43:03.055114",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.024166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_image_predictions = pickle5.load(open(\"../input/fdgfdgdfgdfg/f_image_p.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sound-experience",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.091592Z",
     "iopub.status.busy": "2021-05-09T10:43:03.090970Z",
     "iopub.status.idle": "2021-05-09T10:43:03.093681Z",
     "shell.execute_reply": "2021-05-09T10:43:03.093288Z"
    },
    "papermill": {
     "duration": 0.022455,
     "end_time": "2021-05-09T10:43:03.093783",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.071328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_transforms1():\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size1,CFG.img_size1,always_apply=True),\n",
    "            A.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "descending-socket",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.130996Z",
     "iopub.status.busy": "2021-05-09T10:43:03.130279Z",
     "iopub.status.idle": "2021-05-09T10:43:03.133075Z",
     "shell.execute_reply": "2021-05-09T10:43:03.132563Z"
    },
    "papermill": {
     "duration": 0.023019,
     "end_time": "2021-05-09T10:43:03.133176",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.110157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_transforms2():\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size2,CFG.img_size2,always_apply=True),\n",
    "            A.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charming-there",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.170657Z",
     "iopub.status.busy": "2021-05-09T10:43:03.169952Z",
     "iopub.status.idle": "2021-05-09T10:43:03.172532Z",
     "shell.execute_reply": "2021-05-09T10:43:03.172146Z"
    },
    "papermill": {
     "duration": 0.023021,
     "end_time": "2021-05-09T10:43:03.172649",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.149628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accompanied-detail",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.210786Z",
     "iopub.status.busy": "2021-05-09T10:43:03.210009Z",
     "iopub.status.idle": "2021-05-09T10:43:03.212269Z",
     "shell.execute_reply": "2021-05-09T10:43:03.212655Z"
    },
    "papermill": {
     "duration": 0.023521,
     "end_time": "2021-05-09T10:43:03.212792",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.189271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Gen_color_Img(S, names):\n",
    "    Images = []\n",
    "    for index in range(S):\n",
    "        # Read the raw data\n",
    "        IMG = tf.io.read_file(names[index])\n",
    "        # Decoding the raw data\n",
    "        IMG = tf.io.decode_png(IMG, channels=1)\n",
    "        # Resize the image\n",
    "        IMG = tf.image.resize(IMG, [2048,2048],method='bicubic')\n",
    "        Images.append(IMG)\n",
    "    return Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "satellite-ordinary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.251965Z",
     "iopub.status.busy": "2021-05-09T10:43:03.251269Z",
     "iopub.status.idle": "2021-05-09T10:43:03.254101Z",
     "shell.execute_reply": "2021-05-09T10:43:03.253569Z"
    },
    "papermill": {
     "duration": 0.024661,
     "end_time": "2021-05-09T10:43:03.254202",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.229541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "    \n",
    "        return image,torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reverse-vienna",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.299096Z",
     "iopub.status.busy": "2021-05-09T10:43:03.298392Z",
     "iopub.status.idle": "2021-05-09T10:43:03.305085Z",
     "shell.execute_reply": "2021-05-09T10:43:03.304614Z"
    },
    "papermill": {
     "duration": 0.033758,
     "end_time": "2021-05-09T10:43:03.305186",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.271428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output\n",
    "\n",
    "get_cpkl(pickle.load(open(\"../input/fdgfdgdfgdfg/c_ShopeeModel.pkl\",\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "express-tennessee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.343323Z",
     "iopub.status.busy": "2021-05-09T10:43:03.342627Z",
     "iopub.status.idle": "2021-05-09T10:43:03.345346Z",
     "shell.execute_reply": "2021-05-09T10:43:03.344860Z"
    },
    "papermill": {
     "duration": 0.023492,
     "end_time": "2021-05-09T10:43:03.345441",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.321949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new_parrall(model, model_path):\n",
    "    state = torch.load(model_path, map_location='cuda:0')\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state.items():\n",
    "        k=k[7:]\n",
    "        new_state_dict[k]=v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hydraulic-university",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.386749Z",
     "iopub.status.busy": "2021-05-09T10:43:03.386044Z",
     "iopub.status.idle": "2021-05-09T10:43:03.388244Z",
     "shell.execute_reply": "2021-05-09T10:43:03.388657Z"
    },
    "papermill": {
     "duration": 0.026244,
     "end_time": "2021-05-09T10:43:03.388771",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.362527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths, model_name, model_path, get_test_transforms):\n",
    "    embeds = []\n",
    "    model_arch = model_name\n",
    "    model = ShopeeModel(11014, model_name, False, False)\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    model = new_parrall(model, model_path)\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "saving-reduction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.429965Z",
     "iopub.status.busy": "2021-05-09T10:43:03.429294Z",
     "iopub.status.idle": "2021-05-09T10:43:03.431589Z",
     "shell.execute_reply": "2021-05-09T10:43:03.431971Z"
    },
    "papermill": {
     "duration": 0.026301,
     "end_time": "2021-05-09T10:43:03.432087",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.405786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader,model,optimizer,device,scheduler,epoch):\n",
    "    model.train()\n",
    "    loss_score = AverageMeter()\n",
    "    \n",
    "    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for bi,d in tk0:\n",
    "        \n",
    "        batch_size = d[0].shape[0]\n",
    "\n",
    "        input_ids = d[0]\n",
    "        targets = d[1]\n",
    "\n",
    "        input_ids = input_ids.to(device,dtype=torch.long)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids=input_ids,labels=targets)\n",
    "        \n",
    "        loss = output.loss       \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_score.update(loss.detach().item(), batch_size)\n",
    "        tk0.set_postfix(Train_Loss=loss_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        \n",
    "    return loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promotional-statistics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.473747Z",
     "iopub.status.busy": "2021-05-09T10:43:03.473082Z",
     "iopub.status.idle": "2021-05-09T10:43:03.475336Z",
     "shell.execute_reply": "2021-05-09T10:43:03.475718Z"
    },
    "papermill": {
     "duration": 0.026571,
     "end_time": "2021-05-09T10:43:03.475843",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.449272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_predictions(df, max_features = 25_000):\n",
    "    \n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    preds = []\n",
    "    CHUNK = 1024*4\n",
    "\n",
    "    print('Finding similar titles...')\n",
    "    CTS = len(df)//CHUNK\n",
    "    if len(df)%CHUNK!=0: CTS += 1\n",
    "    for j in range( CTS ):\n",
    "\n",
    "        a = j*CHUNK\n",
    "        b = (j+1)*CHUNK\n",
    "        b = min(b,len(df))\n",
    "        print('chunk',a,'to',b)\n",
    "\n",
    "        # COSINE SIMILARITY DISTANCE\n",
    "        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
    "\n",
    "        for k in range(b-a):\n",
    "            IDX = cupy.where(cts[k,]>0.75)[0]\n",
    "            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "            preds.append(o)\n",
    "    \n",
    "    del model,text_embeddings\n",
    "    gc.collect()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cognitive-peoples",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.518457Z",
     "iopub.status.busy": "2021-05-09T10:43:03.517727Z",
     "iopub.status.idle": "2021-05-09T10:43:03.520302Z",
     "shell.execute_reply": "2021-05-09T10:43:03.519803Z"
    },
    "papermill": {
     "duration": 0.027275,
     "end_time": "2021-05-09T10:43:03.520397",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.493122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Defining DataSet\n",
    "    train_dataset = ShopeeDataset(\n",
    "        csv=data\n",
    "    )\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Defining Model for specific fold\n",
    "    model = AutoModelForMaskedLM.from_pretrained(transformer_model)\n",
    "    print(model)\n",
    "    model.to(device)\n",
    "\n",
    "        \n",
    "    # Defining Optimizer with weight decay to params other than bias and layer norms\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "            ]  \n",
    "    \n",
    "    optimizer = AdamW(optimizer_parameters, lr=LR)\n",
    "    \n",
    "    #Defining LR SCheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=len(train_loader)*5, \n",
    "        num_training_steps=len(train_loader)*EPOCHS\n",
    "    )\n",
    "        \n",
    "    # THE ENGINE LOOP\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = train_fn(train_loader, model,optimizer, device,scheduler=scheduler,epoch=epoch)\n",
    "          \n",
    "    model.save_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reduced-karaoke",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:03.559748Z",
     "iopub.status.busy": "2021-05-09T10:43:03.559123Z",
     "iopub.status.idle": "2021-05-09T10:43:27.771147Z",
     "shell.execute_reply": "2021-05-09T10:43:27.770534Z"
    },
    "papermill": {
     "duration": 24.233244,
     "end_time": "2021-05-09T10:43:27.771279",
     "exception": false,
     "start_time": "2021-05-09T10:43:03.538035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 3072)\n",
      "1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 1536)\n"
     ]
    }
   ],
   "source": [
    "model_arch = CFG.model_name1\n",
    "image_embeddings1 = get_image_embeddings(image_paths.values, model_arch, CFG.model_path1, get_test_transforms1)\n",
    "torch.cuda.empty_cache()\n",
    " \n",
    "model_arch = \"swin_large_patch4_window12_384\"\n",
    "image_embeddings2 = get_image_embeddings(image_paths.values, model_arch, CFG.model_path2, get_test_transforms2)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "otherwise-cancellation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:27.820576Z",
     "iopub.status.busy": "2021-05-09T10:43:27.819820Z",
     "iopub.status.idle": "2021-05-09T10:43:43.974728Z",
     "shell.execute_reply": "2021-05-09T10:43:43.975583Z"
    },
    "papermill": {
     "duration": 16.183067,
     "end_time": "2021-05-09T10:43:43.975808",
     "exception": false,
     "start_time": "2021-05-09T10:43:27.792741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3338.53it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4198.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar titles...\n",
      "chunk 0 to 3\n"
     ]
    }
   ],
   "source": [
    "image_predictions1 = get_image_predictions(df, image_embeddings1, threshold = 0.7, threshold_a=0.2)\n",
    "del image_embeddings1\n",
    "gc.collect()\n",
    "\n",
    "image_predictions2 = get_image_predictions(df, image_embeddings2, threshold = 0.5, threshold_a=0.2)\n",
    "del  image_embeddings2\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "text_predictions = get_text_predictions(df, max_features = 25_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "voluntary-burst",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T10:43:44.060829Z",
     "iopub.status.busy": "2021-05-09T10:43:44.059862Z",
     "iopub.status.idle": "2021-05-09T10:43:44.083927Z",
     "shell.execute_reply": "2021-05-09T10:43:44.084786Z"
    },
    "papermill": {
     "duration": 0.070499,
     "end_time": "2021-05-09T10:43:44.084979",
     "exception": false,
     "start_time": "2021-05-09T10:43:44.014480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['image_predictions1'] = image_predictions1\n",
    "df['image_predictions2'] = image_predictions2\n",
    "df['text_predictions'] = text_predictions\n",
    "df['phash_predictions'] = df.image_phash.map(df.groupby('image_phash').posting_id.agg('unique').to_dict())\n",
    "df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-independence",
   "metadata": {
    "papermill": {
     "duration": 0.039683,
     "end_time": "2021-05-09T10:43:44.165045",
     "exception": false,
     "start_time": "2021-05-09T10:43:44.125362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-architecture",
   "metadata": {
    "papermill": {
     "duration": 0.036746,
     "end_time": "2021-05-09T10:43:44.241837",
     "exception": false,
     "start_time": "2021-05-09T10:43:44.205091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.745534,
   "end_time": "2021-05-09T10:43:47.372942",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-09T10:42:39.627408",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
